---
title: "Forecasting U.S. Presidential Election Outcomes: A Poll-Based Predictive Model Using YouGov Data"
subtitle: "Analyzing the Impact of Political Party, Candidate Name, and Sample Size on Vote Share Predictions"
author: 
  - Yizhe Chen
  - Charlie Zhang
  - Qizhou Xie
thanks: "Code and data are available at: [https://github.com/YizheChenUT/Election_Forecasting_Model.git](https://github.com/YizheChenUT/Election_Forecasting_Model.git)."
date: today
date-format: long
abstract: "This study develops a Bayesian linear regression model to forecast U.S. presidential vote shares using polling data from YouGov, incorporating predictors like political party, candidate name, sample size, and poll end date. Key findings reveal that political party affiliation positively influences vote share, especially for major-party candidates, while candidate-specific characteristics, such as recognition, further impact predictions. Interestingly, sample size and polling end date show limited effects once minimum thresholds are met, suggesting stable voter sentiment over shorter periods and diminishing returns for larger samples. This model highlights the nuanced role of party and candidate factors in election forecasting and suggests directions for refining poll-based predictive models to enhance forecast accuracy."
format: pdf
pdf-engine: pdflatex
number-sections: true
toc: true
bibliography: references.bib
---


```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(rstanarm)
library(modelsummary)
library(kableExtra)
library(arrow)

```


# Introduction
Polling data is integral to shaping public opinion and predicting election outcomes, particularly within democratic societies where political campaigns rely on polls to understand and sway voter preferences. In the context of U.S. presidential elections, the precision of poll-based predictions holds increasing significance for political parties, candidates, and media organizations. However, accurately forecasting election outcomes involves multiple challenges, including the complexity of sample selection, timing, and candidate-specific factors.

This study builds a Bayesian linear regression model to forecast U.S. presidential vote shares using polling data from YouGov, a prominent polling agency. The model includes variables such as political party affiliation, candidate name, sample size, and the poll’s end date. By focusing on a single, high-quality data source, this research isolates the effects of these factors on vote share predictions, thereby contributing to the broader literature on election forecasting.

The primary estimand of this model is the predicted percentage of votes each candidate is expected to receive. The results show that political party affiliation plays a notable role in vote share predictions, with major-party candidates—particularly Republicans—generally receiving higher predicted shares. Additionally, candidate-specific factors like name recognition impact forecasts, while the effect of sample size and polling end date diminishes once a minimum threshold is reached. These findings underline the importance of incorporating both party and candidate characteristics into election models and suggest potential refinements for future poll-based forecasts.

The remainder of this paper is structured as follows: Section @sec-data provides an overview of the data, detailing its sources, cleaning procedures, and key variables like candidate name, political party, sample size, and polling end date. Section @sec-model discusses the model setup and justification, outlining the Bayesian linear regression approach and the rationale behind selecting specific predictors. Section @sec-result presents the results, examining the impact of party affiliation, candidate identity, and other factors on vote share predictions. Visualizations are included to illustrate key trends. Section @sec-disscussion explores broader implications, limitations, and potential extensions of this study, including sample size effects and directions for future research. Finally, sections @sec-appendix1 and @sec-appendix2 provide a detailed analysis of YouGov’s polling methodology and an idealized $100K survey methodology, offering practical views for election forecasting.

# Data {#sec-data}
## Overview
We use the statistical programming language R [@citeR] to process and analyze the polling data sourced from YouGov [@YouGov], one of the leading polling agencies for U.S. elections. We use the httr package to download data [@httr] from the 538 website [@Wiederkehr]. The dataset includes several key variables that are important for predicting the percentage of votes each presidential candidate might receive, such as candidate name, political party, sample size, and the polling end date. Following the approach outlined by @tellingstories, we incorporate both candidate-specific and poll-specific factors to improve the accuracy of our model.

The data was cleaned and processed through the janitor package to ensure that all missing values for the vote percentage (pct) were removed, and categorical variables like candidate name and political party were properly encoded [@janitor]. Additionally, sample sizes and dates were standardized for consistency across all polling entries.

## Measurement
Polling data, in essence, represents a snapshot of public opinion at a given time. In our case, the dataset captures public opinion on various presidential candidates based on responses collected via YouGov's online surveys. These responses are translated into numerical entries in the dataset, such as the predicted percentage of votes a candidate might receive (pct), the number of respondents (sample_size), and the poll's end date (end_date).

## Outcome variables
The primary outcome variable in our dataset is the predicted percentage of votes (pct) for each candidate. This variable is influenced by several factors, including the candidate's political party, the sample size of the poll, and the timing of the poll. To illustrate the distribution of vote percentages for candidates from different political parties, we present the following graph.

```{r}
#| label: fig-vote-share
#| fig-cap: Predicted vote percentage by party
#| echo: false
#| eval: true
#| warning: false
#| message: false

analysis_data <- read_parquet(here::here("data/02-analysis_data/analysis_data.parquet"))

ggplot(analysis_data, aes(x = party, y = pct, fill = party)) +
  geom_boxplot(alpha = 0.8) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal() +
  labs(x = "Political Party", y = "Predicted Vote Percentage")

```

As shown in @fig-vote-share, Republican candidates tend to have a slightly higher predicted vote percentage compared to Democratic candidates across the polls. This is consistent with the trend observed in more recent elections, where party affiliation plays a significant role in influencing voter preferences.

## Sample size
An essential aspect of our data is the sample size, which varies across polls. Generally, larger sample sizes improve prediction reliability by capturing a broader spectrum of voter preferences, thereby reducing variability in vote share estimates. However, our findings reveal that after reaching a certain sample threshold, additional respondents do not significantly impact predicted vote percentages. 

```{r}
#| label: fig-sample-size
#| fig-cap: Relationship between sample size and predicted vote percentage
#| echo: false
#| eval: true
#| warning: false
#| message: false

ggplot(analysis_data, aes(x = sample_size, y = pct)) +
  geom_point(alpha = 0.8) +
  theme_minimal() +
  labs(x = "Sample Size", y = "Predicted Vote Percentage")

```

This result, illustrated in @fig-sample-size, indicates a limited relationship between sample size and vote share predictions, with smaller sample sizes yielding similarly accurate predictions beyond a minimal threshold.

Despite this, the data shows that larger sample sizes can still reveal a wider range of voter preferences. This observation suggests that while increased sample size may not substantially affect the accuracy of the predicted vote share, it could enhance the model's ability to capture nuanced variations in voter opinion, which is particularly valuable in closely contested races where small differences matter.

## Predictor variables
Several predictor variables were included in our model to estimate the percentage of votes for each candidate. These variables include:

- **Political Party (party)**: Whether the candidate belongs to the Democratic, Republican, or other parties.
- **Candidate Name (candidate_name)**: The specific candidate being polled, which can influence vote shares based on their popularity and recognition.
- **Sample Size (sample_size)**: The number of respondents in the poll, which affects the reliability of the vote predictions.
- **Polling End Date (end_date)**: The date when the poll concluded, as public opinion can shift closer to the election date.

The relationships between these predictor variables and the outcome variable were further explored in the following section. We simply explore the distribution of political parties within our dataset.

```{r}
#| label: fig-party-distribution
#| fig-cap: Distribution of political parties in the polling data
#| echo: false
#| eval: true
#| warning: false
#| message: false

ggplot(analysis_data, aes(x = party, fill = party)) +
  geom_bar(alpha = 0.8) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal() +
  labs(x = "Political Party", y = "Number of Polls")

```

In @fig-party-distribution, we see that the dataset contains a relatively balanced number of polls for both major political parties, ensuring that the model predictions are not biased toward one party over the other.

# Model {#sec-model}
The goal of our modeling strategy is twofold. Firstly, we aim to predict the percentage of votes each presidential candidate will receive using polling data from YouGov. Secondly, we seek to understand how key factors—such as political party, candidate name, sample size, and polling end date—affect vote share predictions.

We employ a Bayesian linear regression model to investigate these relationships. The model assumes that the percentage of votes (pct) follows a normal distribution, with predictors including the political party of the candidate, the candidate’s name, the sample size of the poll, and the end date of the poll.

## Model set-up
Define $y_i$ as the predicted percentage of votes for candidate $i$, and $\texttt{party}_i$, $\texttt{candidate}_i$, $\texttt{sample\_size}_i$, and $\texttt{end\_date}_i$ as the political party, candidate name, sample size, and polling end date for candidate $i$ respectively.

The model is formulated as:

$$y_i | \mu_i, \sigma \sim \text{Normal}(\mu_i, \sigma)$$

where

$$\mu_i = \alpha + \beta_1 \cdot \texttt{party}_i + \beta_2 \cdot \texttt{candidate}_i + \beta_3 \cdot \texttt{sample\_size}_i + \beta_4 \cdot \texttt{end\_date}_i$$

- $\alpha$ is the intercept, representing the baseline vote share.
- $\beta_1$, $\beta_2$, $\beta_3$, and $\beta_4$ are the coefficients representing the effect of political party, candidate name, sample size, and polling end date, respectively.

The priors for the parameters are as follows:

$$\alpha \sim \text{Normal}(0, 2.5)$$
$$\beta_1, \beta_2, \beta_3, \beta_4 \sim \text{Normal}(0, 2.5)$$
$$\sigma \sim \text{Exponential}(1)$$

We run the model in R [@citeR] using the rstanarm package [@rstanarm]. The default priors from rstanarm are applied, reflecting weak prior beliefs to allow the data to speak for itself.

## Model justification
We expect a significant relationship between the predictors and the percentage of votes. Specifically, political party is expected to have a substantial impact, as previous polls suggest that party affiliation strongly correlates with voter preferences. Additionally, sample size is an important predictor, as larger sample sizes tend to provide more reliable estimates. Polls conducted closer to the election (end date) may also capture more accurate voter sentiments, leading to better predictions.

The Bayesian approach allows for more flexibility in the modeling process, particularly when accounting for uncertainty in the predictions. The inclusion of candidate-specific and poll-specific factors ensures that the model captures the nuanced dynamics of election forecasting, providing a more comprehensive analysis of polling data.

# Results {#sec-result}
Our results are summarized in @tbl-modelresults by using the modelsummary package [@modelsummary]. The model was designed to predict the percentage of votes each presidential candidate might receive based on several key factors: political party, candidate name, sample size, and polling end date. Below, we present a table of the model's coefficients, followed by visualizations of the relationship between the predictors and the predicted vote share.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false


# Load the model
first_model <- readRDS(file = here::here("models/final_model.rds"))

```


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: tbl-modelresults
#| tbl-cap: "Models of vote percentage based on party, candidate name, sample size, and end date"

modelsummary::modelsummary(
  list(
    "Vote Share Prediction Model" = first_model
  ),
  statistic = "mad",  # Mean absolute deviation
  fmt = 2  # Format to 2 decimal places
)%>%
  kableExtra::kable_styling(font_size = 8, full_width = TRUE)
```

The table above (@tbl-modelresults) provides the estimated coefficients for each of the predictors in the model. We observe that the intercept is negative, and while certain candidate names, like Kamala Harris and Joe Biden, show positive coefficients, their effect sizes are not very large. The coefficient for the Republican party is positive but small (4.33), and several third-party candidates like Jill Stein and Cornel West show negative coefficients, which indicates lower predicted vote percentages.

Moreover, both sample size and end date have coefficients very close to zero, suggesting that these factors do not have a significant impact on the predicted vote percentages in this model.

## Key Findings
- Political Party: The results show that the Republican party has a small positive effect on vote share predictions, while third-party candidates generally have lower predicted percentages.

- Candidate Name: Certain candidates, such as Kamala Harris and Joe Biden, have positive coefficients, indicating a higher predicted vote share compared to other candidates like Mike Pence and Vivek Ramaswamy, who show negative coefficients.

- Sample Size and Poll End Date: The coefficients for sample size and poll end date are effectively zero, suggesting they do not have a meaningful effect on the vote predictions.

## Visualization of Results
We now turn to graphical representations to illustrate the relationship between sample size and predicted vote percentage, as well as the effect of political party on the predicted vote share.

```{r}
#| label: fig-sample-vote
#| fig-cap: "Relationship between sample size and predicted vote percentage"
#| echo: false
#| warning: false
#| message: false

ggplot(analysis_data, aes(x = sample_size, y = pct)) +
  geom_point(alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  theme_minimal() +
  labs(x = "Sample Size", y = "Predicted Vote Percentage")

```

In @fig-sample-vote, we observe that there is no strong relationship between sample size and predicted vote share, as evidenced by the flat regression line. This supports the finding from the model coefficients, where the effect of sample size on vote predictions is negligible.

```{r}
#| label: fig-party-vote
#| fig-cap: "Predicted vote percentage by political party"
#| echo: false
#| warning: false
#| message: false

ggplot(analysis_data, aes(x = party, y = pct, fill = party)) +
  geom_boxplot(alpha = 0.8) +
  theme_minimal() +
  labs(x = "Political Party", y = "Predicted Vote Percentage")

```
In @fig-party-vote, the distribution of predicted vote percentages by political party is shown. The model indicates that Republican candidates generally receive a higher predicted vote share compared to Democratic candidates. Third-party candidates, such as those from the Green and Independent parties, tend to have significantly lower predicted vote percentages.

# Discussion {#sec-disscussion}
## Overview of Findings
In this paper, we built a predictive model to estimate the vote share of U.S. presidential candidates using polling data, with key predictors including political party, candidate name, sample size, and polling end date. The goal was to understand how these factors influence predicted vote shares, and to gain understanding on the dynamics of political polling. The model’s high $R^2$ value (0.964) indicates it explains a substantial amount of variation in vote predictions, suggesting that it successfully captures relevant trends in the data. This outcome offers a deeper understanding of the factors driving poll-based vote share predictions in U.S. elections.

## Political Influence on Vote Share
One key finding from this analysis is the impact of political party on vote share predictions. Our model indicates that candidates from major parties, particularly Republicans, tend to receive higher predicted vote shares compared to third-party candidates. This is consistent with historical trends, where major-party candidates generally dominate U.S. elections. The model reinforces the idea that party affiliation is a powerful determinant in voter preferences, reflecting the established influence of major parties in American politics. This finding aligns with broader theories in political science, where party affiliation often serves as a shortcut for voters, helping them make quick decisions about candidates based on their general political orientation.

## Candidate-Specific Effects on Vote Share
Another important takeaway is the effect of candidate-specific factors on vote share predictions. Certain candidates, such as Joe Biden and Kamala Harris, show positive coefficients, indicating they are expected to receive a higher share of votes compared to others like Mike Pence or Vivek Ramaswamy. This suggests that individual characteristics and name recognition may play a role in influencing voter support. Recognizable figures with established reputations, such as former presidents or vice presidents, may have an advantage in polls due to higher visibility and public familiarity. This finding highlights the importance of candidate characteristics beyond party affiliation and points to the potential value of including more candidate-specific variables, such as favorability ratings, in future models.

## Limitations of Sample Size and Polling End Date as Predictors
Despite the high explanatory power of the model, certain predictors—particularly sample size and polling end date—show little to no effect on vote share predictions. This result might initially seem counterintuitive, as larger sample sizes are generally associated with higher reliability in survey research. However, in this case, the lack of impact could suggest that once a minimum sample threshold is met, the additional respondents do not significantly alter the predicted vote share. Similarly, the end date of the poll may have little impact because public opinion might not shift drastically over short periods, especially if polling occurs well before the election. This raises questions about the utility of these predictors in vote share models and suggests that additional contextual factors, such as the timing of major political events, could be more meaningful.

## Weaknesses and Next Steps
While this model provides valuable findings, it also has some limitations. First, the model does not incorporate a variable for state-level differences, which could be significant in the U.S. electoral system, where the Electoral College, not the popular vote, ultimately determines the election outcome. A more detailed model could include state as a predictor or even focus on state-level vote shares to estimate Electoral College outcomes.

Additionally, our model lacks dynamic elements, such as shifts in public opinion over time, which could be particularly relevant in the lead-up to an election. Future models might address this by incorporating temporal factors or polling trends over several months, capturing how voter sentiment changes as the election date approaches.

Finally, the model only uses data from one pollster, YouGov, which may limit the generalizability of the findings. Different pollsters have varying methodologies, sampling frames, and biases, all of which can influence poll results. Future research could incorporate data from multiple pollsters, applying a poll-aggregation approach to mitigate individual poll biases and improve overall prediction accuracy.

## Concluding Remarks and Future Directions
This analysis contributes to our understanding of how polling data can be used to predict election outcomes, highlighting the importance of political party and candidate characteristics in influencing vote shares. However, there remains much to explore. Future research could expand on this model by integrating additional predictors, such as candidate favorability and recent political events, or by building state-level models to predict Electoral College outcomes.

In conclusion, while the current model provides a useful framework for analyzing vote share predictions, expanding its scope and incorporating new data sources could further enhance its predictive power and applicability. Understanding the nuances of voter behavior and poll-based predictions remains an important area of research, especially in the context of modern elections where polling plays a central role in shaping public perception and media narratives.

\newpage

\appendix

# Appendix {-}
# Detailed Analysis of YouGov's Polling Methodology {#sec-appendix1}
## Overview of YouGov's Polling Approach
YouGov is a prominent polling agency known for its methodological rigor and unique approach to online surveys [@YouGov]. This appendix delves into YouGov's methodology, examining its sample selection, recruitment techniques, and the reliability and limitations inherent in its survey process.

## Population, Frame, and Sample
The population targeted by YouGov’s polls comprises U.S. adult citizens, providing a frame that includes diverse demographics such as age, gender, race, income level, and political affiliation [@YouGov]. The samples are drawn from an online panel of respondents who voluntarily participate in YouGov’s surveys [@YouGov]. By using an extensive online panel, YouGov strives to capture a broad, representative slice of public opinion on various political issues, including presidential election intent, candidate favorability, and policy priorities.

## Sampling and Recruitment
YouGov employs a non-probability sampling approach, specifically targeting individuals within its online panel [@YouGov]. While this method allows YouGov to reach a large and diverse set of respondents quickly, it introduces certain limitations in terms of randomization and representativeness compared to traditional random sampling methods. To mitigate these issues, YouGov uses sophisticated weighting techniques to adjust for demographic discrepancies, ensuring that the sample more accurately reflects the broader U.S. population.

## Sampling Approach: Trade-offs
The online nature of YouGov’s panel sampling allows for rapid and frequent polling. However, it also comes with trade-offs, particularly concerning coverage bias, as individuals without internet access or those less inclined to participate in online activities may be underrepresented. Additionally, while weighting adjustments improve representativeness, they cannot entirely compensate for the self-selection bias inherent in voluntary panel participation. This trade-off is a key factor to consider when interpreting results, as online samples may sometimes diverge from outcomes in broader, random-sample-based polls.

## Non-response Handling
To address potential non-response bias, YouGov employs weighting adjustments based on demographic factors such as age, gender, education, and political affiliation [@YouGov]. By adjusting responses according to these factors, YouGov attempts to balance out any biases introduced by individuals who choose not to respond to specific questions or surveys entirely. This weighting process helps align the sample's characteristics with the intended population, although it does not completely eliminate non-response bias.

## Questionnaire Design
YouGov’s questionnaires are carefully crafted to gather specific information about voters’ opinions on candidates, political parties, and policy issues. The questions are standardized to allow comparison over time, aiding trend analysis. However, the online format of the questionnaire could impact responses, as participants are aware they are not in a monitored, controlled setting. Despite this limitation, YouGov’s design ensures clarity and consistency, although some complex topics may benefit from further simplification to enhance understanding across diverse education levels.

## Strengths and Weaknesses
### Strengths
- Speed and Flexibility: The online sampling and recruitment model enables YouGov to conduct polls swiftly, which is particularly valuable in fast-moving political contexts.

- Cost Efficiency: Online polling reduces costs compared to phone or face-to-face methods, allowing for frequent and large-scale surveys.

- Data Adjustments: The extensive use of weighting to adjust for demographic characteristics adds robustness to the results and aids in achieving more representative findings.

### Weaknesses
- Selection Bias: As participants self-select into the online panel, there is an inherent selection bias that even weighting cannot fully mitigate.

- Underrepresentation of Offline Populations: People without internet access or less inclination toward online activities are potentially underrepresented.

- Complexity of Weighting Models: While weighting is beneficial, the reliance on these adjustments can sometimes introduce additional uncertainties, especially if the sample is not fully aligned with demographic expectations.


# Idealized Methodology and Survey for Forecasting the U.S. Presidential Election {#sec-appendix2}
This appendix provides a detailed methodology for conducting an election forecasting survey with a $100,000 budget. The methodology focuses on achieving representativeness, accuracy, and data quality. The survey includes stratified sampling, multi-channel recruitment, data validation, and careful questionnaire design, implemented via Google Forms.

## Methodology Overview
This survey aims to forecast U.S. presidential election outcomes by capturing voting intentions and priorities across various demographic groups. With a $100,000 budget, we estimate reaching a sample size of approximately 5,000 respondents. This funding covers recruitment, incentives, and platform usage costs, ensuring a robust dataset that represents the U.S. voting population.

## Sampling Approach
Stratified Random Sampling will be employed, focusing on:

- Stratification Variables: Age, gender, race, income, education, and geography.

- Sample Size: With the $100K budget, the target sample size is approximately 5,000 respondents, based on cost estimates for recruitment, incentives, and platform usage.

- Random Selection: Participants will be randomly selected within each stratum to ensure demographic balance.

The stratified random sampling method is ideal for this survey because it enhances the representativeness of the sample across key demographics, reducing potential biases associated with online-only recruitment.

## Recruitment Strategy
To reach a diverse population of respondents, the survey will use multi-channel recruitment, including:

- Social Media Advertising: Targeted ads on platforms such as Facebook, Twitter, and Instagram, directed toward U.S. users of various demographics.

- Email Outreach: Partnerships with organizations that can share the survey link with their networks.

- Incentives: Respondents will receive a small monetary incentive (e.g., $10 gift card) upon completing the survey, increasing participation rates while staying within budget.

By utilizing multiple recruitment channels, the survey aims to reduce selection bias and capture a broad range of opinions.

## Data Validation and Quality Control
To ensure data accuracy, several quality control measures will be in place:

- Screening Questions: Initial questions to confirm eligibility (e.g., age, U.S. citizenship).

- Attention Checks: Questions designed to ensure respondents are paying attention, helping filter out low-quality responses.

- Duplicate Responses: IP tracking and other technical measures to prevent duplicate submissions.

- Post-Survey Weighting: To correct for any imbalances in the sample, responses will be weighted based on demographic factors according to U.S. Census data, ensuring the final results better reflect the general population.

## Poll Aggregation and Reporting
This survey will be conducted in waves, with data collected at regular intervals leading up to the election. Results from each wave will be aggregated to provide a rolling average of voting intentions, smoothing out anomalies and highlighting trends. This approach will allow the survey to detect shifts in public opinion as the election approaches, providing a dynamic view of voter sentiment.

## Survey Implementation and Structure
The survey will be implemented using Google Forms, which offers a user-friendly interface, data security, and easy access for respondents across devices. Below is the structure and sample questions included in the survey.

## Survey Design
### Introductory Section
**Introduction**

Thank you for participating in our U.S. presidential election survey. Your responses will help us understand voting trends across the country. All responses are anonymous.

**Contact Information** 

For questions, contact us at yz.chen@mail.utoronto.ca

### Consent
By participating, you confirm you are a U.S. citizen aged 18 or older.
[Yes, I confirm I am a U.S. citizen aged 18 or older./No. You cannot participate in our U.S. presidential election survey.]

### Demographic Information
- Age:
[18-24, 25-34, 35-44, 45-54, 55-64, 65+]

- Gender:
[Male, Female, Non-binary, Prefer not to say]

- Race/Ethnicity:
[White, Black or African American, Hispanic or Latino, Asian, Native American, Other]

- Education Level:
[High school or less, Some college, Bachelor’s degree, Master’s degree, Doctoral degree]

- Income Range:
[Under $25,000, $25,000-$49,999, $50,000-$74,999, $75,000-$99,999, $100,000+]

- State of Residence:
[Drop-down list of all U.S. states]

### Voter Intentions
- Which candidate do you currently support in the upcoming presidential election?
[List of major candidates, including “Undecided”]

- How strongly do you support this candidate?
[1 = Not strongly, 5 = Very strongly]

- Have you made a final decision, or could you change your mind before the election?
[Final decision, Could change mind, Prefer not to say]

### Political Priorities
- Which issues are most important to you in this election? (Select up to 3)
[Economy, Healthcare, Immigration, Education, Climate Change, National Security, Other]

- How satisfied are you with the current state of the U.S. economy?
[1 = Very dissatisfied, 5 = Very satisfied]

- How important is healthcare policy in your decision for whom to vote?
[1 = Not important, 5 = Very important]

### Electoral Process and Trust
- How likely are you to vote in the upcoming presidential election?
[Definitely, Probably, Probably not, Definitely not]

- How much trust do you have in the electoral process?
[1 = No trust, 5 = Complete trust]

- In general, do you believe your vote will make a difference?
[Yes, No, Unsure]

### Additional Political Views
- Do you think the country is headed in the right direction or on the wrong track?
[Right direction, Wrong track, Unsure]

- How would you describe your political ideology?
[Very conservative, Conservative, Moderate, Liberal, Very liberal, Prefer not to say]

### Conclusion Section
Thank You Note: “Thank you for completing this survey. Your responses are invaluable to our research on voter sentiment. For questions or results updates, contact yz.chen@mail.utoronto.ca.”

## Link to Survey
[https://forms.gle/6CDa9QGX7aDKgwV78](https://forms.gle/6CDa9QGX7aDKgwV78)

## Summary
This survey methodology provides a comprehensive approach to election forecasting by using stratified sampling, diverse recruitment, and thorough data validation. Structured with an engaging introductory section, well-ordered questions, and a respectful conclusion, this survey is designed to optimize response rates while yielding reliable findings on voter intentions and priorities. The iterative wave structure enables tracking of changes in sentiment over time, supporting a dynamic understanding of public opinion as the election date approaches.


\newpage


# References


